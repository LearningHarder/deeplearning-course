{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e05291d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as  transforms\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from torchsummary import summary\n",
    "from torch.autograd import Variable\n",
    "import time as time\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7684f40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train = datasets.CIFAR100(root='./data/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test = datasets.CIFAR100(root='./data/', train=False, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abce2bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import alexnet\n",
    "import augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ab4c98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1579077e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-a0eb4aca92244d39\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-a0eb4aca92244d39\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f9b60d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 显示网络参数量\n",
    "def Init_net():\n",
    "    model = alexnet.AlexNet()\n",
    "    data_input = Variable(torch.randn(8,3,32,32))\n",
    "    print(data_input.size())\n",
    "    model(data_input)\n",
    "    print(summary(model,(3,32,32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c90c918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 32, 32])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 96, 16, 16]           7,296\n",
      "              ReLU-2           [-1, 96, 16, 16]               0\n",
      " LocalResponseNorm-3           [-1, 96, 16, 16]               0\n",
      "         MaxPool2d-4             [-1, 96, 8, 8]               0\n",
      "            Conv2d-5            [-1, 256, 8, 8]         614,656\n",
      "              ReLU-6            [-1, 256, 8, 8]               0\n",
      " LocalResponseNorm-7            [-1, 256, 8, 8]               0\n",
      "         MaxPool2d-8            [-1, 256, 4, 4]               0\n",
      "            Conv2d-9            [-1, 384, 4, 4]         885,120\n",
      "             ReLU-10            [-1, 384, 4, 4]               0\n",
      "           Conv2d-11            [-1, 384, 4, 4]       1,327,488\n",
      "             ReLU-12            [-1, 384, 4, 4]               0\n",
      "           Conv2d-13            [-1, 384, 4, 4]       1,327,488\n",
      "             ReLU-14            [-1, 384, 4, 4]               0\n",
      "        MaxPool2d-15            [-1, 384, 2, 2]               0\n",
      "          Dropout-16                 [-1, 1536]               0\n",
      "           Linear-17                 [-1, 1536]       2,360,832\n",
      "             ReLU-18                 [-1, 1536]               0\n",
      "          Dropout-19                 [-1, 1536]               0\n",
      "           Linear-20                 [-1, 1536]       2,360,832\n",
      "             ReLU-21                 [-1, 1536]               0\n",
      "           Linear-22                  [-1, 100]         153,700\n",
      "================================================================\n",
      "Total params: 9,037,412\n",
      "Trainable params: 9,037,412\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.38\n",
      "Params size (MB): 34.47\n",
      "Estimated Total Size (MB): 35.87\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "Init_net()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b649a64d",
   "metadata": {},
   "source": [
    "### 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6f1c09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e1167c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_iter in range(100):\n",
    "    writer.add_scalar('Loss/train', np.random.random(), n_iter)\n",
    "    writer.add_scalar('Loss/test', np.random.random(), n_iter)\n",
    "    writer.add_scalar('Accuracy/train', np.random.random(), n_iter)\n",
    "    writer.add_scalar('Accuracy/test', np.random.random(), n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "bdb3d748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-2af65f83dc35544c\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-2af65f83dc35544c\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a7114fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = alexnet.AlexNet()\n",
    "datasets={'train':train,'test':test}\n",
    "dataloaders = { x:DataLoader(datasets[x],batch_size=100,shuffle=True) for x in ['train','test']}\n",
    "optimizerAdam = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c33bc883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ea9cce1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Softmax(dim=1)\n",
    "input = torch.randn(2, 3)\n",
    "output = m(input)\n",
    "_, preds = torch.max(output,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "34cf4c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2515,  0.4354,  0.1378],\n",
       "        [-1.2044, -1.2540,  0.5142]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9382c737",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR100\n",
       "    Number of datapoints: 10000\n",
       "    Split: test\n",
       "    Root Location: ./data/\n",
       "    Transforms (if any): ToTensor()\n",
       "    Target Transforms (if any): None"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "07ea4baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000, 1.0000, 1.0000,  ..., 0.7647, 0.8314, 0.7137],\n",
       "         [1.0000, 0.9961, 0.9961,  ..., 0.6667, 0.6314, 0.5725],\n",
       "         [1.0000, 0.9961, 1.0000,  ..., 0.7412, 0.6510, 0.4745],\n",
       "         ...,\n",
       "         [0.5804, 0.5569, 0.5490,  ..., 0.1176, 0.2549, 0.2980],\n",
       "         [0.4784, 0.4706, 0.4941,  ..., 0.0863, 0.3804, 0.5529],\n",
       "         [0.3412, 0.3451, 0.3961,  ..., 0.1333, 0.4118, 0.5412]],\n",
       "\n",
       "        [[1.0000, 1.0000, 1.0000,  ..., 0.8039, 0.8784, 0.7608],\n",
       "         [1.0000, 0.9961, 0.9961,  ..., 0.6902, 0.6588, 0.6039],\n",
       "         [1.0000, 0.9961, 1.0000,  ..., 0.7804, 0.6980, 0.5216],\n",
       "         ...,\n",
       "         [0.7255, 0.7137, 0.7020,  ..., 0.0667, 0.2431, 0.3020],\n",
       "         [0.6157, 0.6078, 0.6275,  ..., 0.0627, 0.4392, 0.6314],\n",
       "         [0.4784, 0.4784, 0.5255,  ..., 0.1412, 0.5216, 0.6784]],\n",
       "\n",
       "        [[1.0000, 1.0000, 1.0000,  ..., 0.7569, 0.8000, 0.6549],\n",
       "         [1.0000, 0.9961, 0.9961,  ..., 0.5882, 0.5098, 0.4431],\n",
       "         [1.0000, 0.9961, 1.0000,  ..., 0.6627, 0.5098, 0.3412],\n",
       "         ...,\n",
       "         [0.3098, 0.2235, 0.2353,  ..., 0.0039, 0.0588, 0.0784],\n",
       "         [0.2588, 0.2275, 0.2784,  ..., 0.0118, 0.2196, 0.3412],\n",
       "         [0.1608, 0.1529, 0.2196,  ..., 0.0392, 0.2314, 0.3098]]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e61f08dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(train, batch_size=100, shuffle=False)\n",
    "dataloader_test = DataLoader(test, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "6efbf8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,num_epochs=500):\n",
    "    optimizerAdam = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    lossFunc = nn.functional.binary_cross_entropy\n",
    "    since = time.time()\n",
    "    best_acc = 0.0\n",
    "    losses = []\n",
    "    accs = []\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch{}/{}'.format(epoch,num_epochs-1))\n",
    "        \n",
    "        for step,(inputs,labels) in enumerate(dataloader_train):\n",
    "            model.train()\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            labels_onehot =(torch.tensor(np.eye(100)[labels.cpu()],dtype=torch.float32)).to(device)\n",
    "            outputs = model(inputs)\n",
    "            y = nn.Softmax(dim=1)(outputs)\n",
    "            preds = torch.max(outputs.data,1)[1].cpu().numpy() ##取每行最大\n",
    "            train_loss = lossFunc(y, labels_onehot)\n",
    "\n",
    "            optimizerAdam.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizerAdam.step()\n",
    "            losses.append(train_loss)\n",
    "\n",
    "            if step % 100 == 0:\n",
    "                test_accuracy = 0\n",
    "                for step2,(inputs_test,labels_test) in enumerate(dataloader_test):\n",
    "                    model.eval()\n",
    "                    inputs_test = inputs_test.to(device)\n",
    "                    labels_test = labels_test.to(device)\n",
    "                    output_test = model(inputs_test)\n",
    "                    y_test = nn.Softmax(dim=1)(output_test)\n",
    "                    _, pred_test = torch.max(y_test.data, 1)\n",
    "                    test_accuracy = accuracy_score(labels_test, pred_test)\n",
    "                    \n",
    "                accs.append(test_accuracy)\n",
    "                print('step:',step)\n",
    "                print('test accuracy:', test_accuracy)\n",
    "                if test_accuracy > best_acc:\n",
    "                    best_acc = test_accuracy\n",
    "  \n",
    "                \n",
    "    for i in range(len(losses)):\n",
    "        writer.add_scalar(\"Loss/train\",losses[i],i)  \n",
    "    for j in range(len(accs)):\n",
    "        writer.add_scalar(\"Accuracy/test\",accs[i],i)  \n",
    "    \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Trainning complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60 , time_elapsed % 60\n",
    "    ))\n",
    "    print('Best test Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "cc98dc27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch0/499\n",
      "step: 0\n",
      "test accuracy: 0.01\n",
      "step: 100\n",
      "test accuracy: 0.02\n",
      "step: 200\n",
      "test accuracy: 0.0\n",
      "step: 300\n",
      "test accuracy: 0.0\n",
      "step: 400\n",
      "test accuracy: 0.01\n",
      "Epoch1/499\n",
      "step: 0\n",
      "test accuracy: 0.0\n",
      "step: 100\n",
      "test accuracy: 0.0\n",
      "step: 200\n",
      "test accuracy: 0.0\n",
      "step: 300\n",
      "test accuracy: 0.0\n",
      "step: 400\n",
      "test accuracy: 0.01\n",
      "Epoch2/499\n",
      "step: 0\n",
      "test accuracy: 0.0\n",
      "step: 100\n",
      "test accuracy: 0.0\n",
      "step: 200\n",
      "test accuracy: 0.0\n",
      "step: 300\n",
      "test accuracy: 0.0\n",
      "step: 400\n",
      "test accuracy: 0.01\n",
      "Epoch3/499\n",
      "step: 0\n",
      "test accuracy: 0.0\n",
      "step: 100\n",
      "test accuracy: 0.0\n",
      "step: 200\n",
      "test accuracy: 0.0\n",
      "step: 300\n",
      "test accuracy: 0.0\n",
      "step: 400\n",
      "test accuracy: 0.01\n",
      "Epoch4/499\n",
      "step: 0\n",
      "test accuracy: 0.0\n",
      "step: 100\n",
      "test accuracy: 0.0\n",
      "step: 200\n",
      "test accuracy: 0.0\n",
      "step: 300\n",
      "test accuracy: 0.0\n",
      "step: 400\n",
      "test accuracy: 0.01\n",
      "Epoch5/499\n",
      "step: 0\n",
      "test accuracy: 0.0\n",
      "step: 100\n",
      "test accuracy: 0.0\n",
      "step: 200\n",
      "test accuracy: 0.0\n",
      "step: 300\n",
      "test accuracy: 0.0\n",
      "step: 400\n",
      "test accuracy: 0.01\n",
      "Epoch6/499\n",
      "step: 0\n",
      "test accuracy: 0.0\n",
      "step: 100\n",
      "test accuracy: 0.0\n",
      "step: 200\n",
      "test accuracy: 0.0\n",
      "step: 300\n",
      "test accuracy: 0.0\n",
      "step: 400\n",
      "test accuracy: 0.01\n",
      "Epoch7/499\n",
      "step: 0\n",
      "test accuracy: 0.0\n",
      "step: 100\n",
      "test accuracy: 0.0\n",
      "step: 200\n",
      "test accuracy: 0.0\n",
      "step: 300\n",
      "test accuracy: 0.0\n",
      "step: 400\n",
      "test accuracy: 0.01\n",
      "Epoch8/499\n",
      "step: 0\n",
      "test accuracy: 0.0\n",
      "step: 100\n",
      "test accuracy: 0.0\n",
      "step: 200\n",
      "test accuracy: 0.0\n",
      "step: 300\n",
      "test accuracy: 0.0\n",
      "step: 400\n",
      "test accuracy: 0.01\n",
      "Epoch9/499\n",
      "step: 0\n",
      "test accuracy: 0.0\n",
      "step: 100\n",
      "test accuracy: 0.0\n",
      "step: 200\n",
      "test accuracy: 0.0\n",
      "step: 300\n",
      "test accuracy: 0.0\n",
      "step: 400\n",
      "test accuracy: 0.01\n",
      "Epoch10/499\n",
      "step: 0\n",
      "test accuracy: 0.0\n",
      "step: 100\n",
      "test accuracy: 0.0\n",
      "step: 200\n",
      "test accuracy: 0.0\n",
      "step: 300\n",
      "test accuracy: 0.0\n",
      "step: 400\n",
      "test accuracy: 0.01\n",
      "Epoch11/499\n",
      "step: 0\n",
      "test accuracy: 0.0\n",
      "step: 100\n",
      "test accuracy: 0.0\n",
      "step: 200\n",
      "test accuracy: 0.0\n",
      "step: 300\n",
      "test accuracy: 0.0\n",
      "step: 400\n",
      "test accuracy: 0.01\n",
      "Epoch12/499\n",
      "step: 0\n",
      "test accuracy: 0.0\n",
      "step: 100\n",
      "test accuracy: 0.0\n",
      "step: 200\n",
      "test accuracy: 0.0\n",
      "step: 300\n",
      "test accuracy: 0.0\n",
      "step: 400\n",
      "test accuracy: 0.01\n",
      "Epoch13/499\n",
      "step: 0\n",
      "test accuracy: 0.0\n",
      "step: 100\n",
      "test accuracy: 0.0\n",
      "step: 200\n",
      "test accuracy: 0.0\n",
      "step: 300\n",
      "test accuracy: 0.0\n",
      "step: 400\n",
      "test accuracy: 0.01\n",
      "Epoch14/499\n",
      "step: 0\n",
      "test accuracy: 0.0\n",
      "step: 100\n",
      "test accuracy: 0.0\n",
      "step: 200\n",
      "test accuracy: 0.0\n",
      "step: 300\n",
      "test accuracy: 0.0\n",
      "step: 400\n",
      "test accuracy: 0.01\n",
      "Epoch15/499\n",
      "step: 0\n",
      "test accuracy: 0.0\n",
      "step: 100\n",
      "test accuracy: 0.0\n",
      "step: 200\n",
      "test accuracy: 0.0\n",
      "step: 300\n",
      "test accuracy: 0.0\n",
      "step: 400\n",
      "test accuracy: 0.01\n",
      "Epoch16/499\n",
      "step: 0\n",
      "test accuracy: 0.0\n",
      "step: 100\n",
      "test accuracy: 0.0\n",
      "step: 200\n",
      "test accuracy: 0.0\n",
      "step: 300\n",
      "test accuracy: 0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pr/fszw1bfs4l3_gds2ksx8rnbr0000gn/T/ipykernel_36561/2596139905.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbaseline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/pr/fszw1bfs4l3_gds2ksx8rnbr0000gn/T/ipykernel_36561/3350225191.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, num_epochs)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0moptimizerAdam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0moptimizerAdam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/pytorch_env/lib/python3.9/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/pytorch_env/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "baseline = train_model(model,num_epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715f29b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ba2a76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6b18b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7846f55c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "acf00b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoc0/0\n",
      "----------\n",
      "0\n",
      "tensor([59, 14, 14, 59, 14, 61, 14, 14, 13, 61, 14, 59, 14, 14, 59, 14, 61, 14,\n",
      "        14, 59, 61, 59, 61, 59, 59, 61, 14, 14, 14, 14, 59, 97, 59, 14, 14, 61,\n",
      "        14, 14, 14, 14, 14, 14, 14, 14, 14, 61, 14, 14, 14, 97, 14, 14, 14, 14,\n",
      "        61, 13, 61, 59, 61, 59, 14, 14, 14, 14, 14, 14, 14, 61, 61, 14, 61, 14,\n",
      "        14, 61, 14, 13, 14, 13, 59, 59, 61, 61, 14, 14, 14, 14, 14, 14, 14, 14,\n",
      "        14, 53, 59, 14, 14, 14, 59, 14, 59, 59])\n",
      "test accuracy: 0.0102\n",
      "1\n",
      "tensor([ 6, 61, 61, 61,  6, 61, 61,  6,  6, 61, 61,  6,  6,  6, 61, 61,  6,  6,\n",
      "         6, 61,  6, 71,  6, 61, 61,  6, 61,  6, 71,  6,  6, 61, 61,  6, 61, 61,\n",
      "         6, 61, 61,  6, 61,  6,  6, 61, 71, 61, 61,  6,  6, 61, 61,  6,  6,  6,\n",
      "         6, 61,  6,  6,  6,  6,  6, 61, 61,  6, 61,  6,  6, 71, 61, 61, 61, 61,\n",
      "         6, 61,  6, 61,  6,  6, 61, 61, 61,  6, 61,  6,  6, 61,  6, 61, 61,  6,\n",
      "        61,  6,  6,  6,  6,  6, 61,  6,  6,  6])\n",
      "2\n",
      "tensor([71, 61, 61, 61, 71, 61, 71, 61, 61, 61, 61, 71, 61, 61, 61, 71, 61, 61,\n",
      "        61, 61, 71, 61, 61, 71, 61, 61, 71, 61, 61, 61, 71, 61, 61, 71, 61, 61,\n",
      "        61, 71, 61, 61, 71, 71, 71, 61, 61, 61, 61, 61, 71, 61, 61, 61, 61, 71,\n",
      "        61, 71, 61, 61, 61, 71, 61, 61, 61, 71, 61, 61, 71, 61, 61, 71, 61, 61,\n",
      "        61, 61, 71, 61, 61, 61, 71, 61, 61, 61, 61, 61, 61, 71, 61, 61, 61, 71,\n",
      "        71, 61, 71, 71, 71, 61, 61, 61, 61, 61])\n",
      "3\n",
      "tensor([61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
      "        61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
      "        61, 61, 61, 61, 61, 61, 61, 71, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
      "        61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
      "        61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
      "        61, 61, 61, 61, 61, 61, 61, 61, 61, 61])\n",
      "4\n",
      "tensor([61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
      "        61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
      "        61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
      "        61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
      "        61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
      "        61, 61, 61, 61, 61, 61, 61, 61, 61, 61])\n",
      "5\n",
      "tensor([61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
      "        61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
      "        61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
      "        61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
      "        61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
      "        61, 61, 61, 61, 61, 61, 61, 61, 61, 61])\n",
      "6\n",
      "tensor([61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
      "        61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
      "        61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
      "        61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
      "        61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
      "        61, 61, 61, 61, 61, 61, 61, 61, 61, 61])\n",
      "7\n",
      "tensor([61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
      "        61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
      "        61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
      "        61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
      "        61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
      "        61, 61, 61, 61, 61, 61, 61, 61, 61, 61])\n",
      "8\n",
      "tensor([61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
      "        61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
      "        61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
      "        61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
      "        61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
      "        61, 61, 61, 61, 61, 61, 61, 61, 61, 61])\n",
      "9\n",
      "tensor([61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
      "        61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
      "        61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
      "        61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
      "        61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
      "        61, 61, 61, 61, 61, 61, 61, 61, 61, 61])\n",
      "10\n",
      "tensor([61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
      "        61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
      "        61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
      "        61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
      "        61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
      "        61, 61, 61, 61, 61, 61, 61, 61, 61, 61])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pr/fszw1bfs4l3_gds2ksx8rnbr0000gn/T/ipykernel_36561/837083894.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0moptimizerAdam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0moptimizerAdam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/pytorch_env/lib/python3.9/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/pytorch_env/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lossFunc = nn.functional.binary_cross_entropy\n",
    "since = time.time()\n",
    "best_acc = 0.0\n",
    "loss=[]\n",
    "accu=[]\n",
    "num=1\n",
    "for epoch in range(num):\n",
    "    print('Epoc{}/{}'.format(epoch,num-1))\n",
    "    print('-'*10)\n",
    "    # epoch一次完成后切换到测试phase\n",
    "\n",
    "    for step,(inputs,labels) in enumerate(dataloader):\n",
    "        model.train()\n",
    "        print(step)\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        labels_onehot =(torch.tensor(np.eye(100)[labels],dtype=torch.float32)).to(device)\n",
    "        outputs = model(inputs)\n",
    "        y = nn.Softmax(dim=1)(outputs)\n",
    "        _, preds = torch.max(y.data,1) ##取每行最大\n",
    "        print(preds)\n",
    "        train_loss = lossFunc(y, labels_onehot)\n",
    "\n",
    "        optimizerAdam.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizerAdam.step()\n",
    "        loss.append(train_loss)\n",
    "        if step % 100 == 0:\n",
    "            for step2,(inputs_test,labels_test) in enumerate(da):\n",
    "                \n",
    "                output = model(inputs_test)\n",
    "                _, pred = torch.max(output, 1)\n",
    "            test_accuracy = accuracy_score(labels_test, pred)\n",
    "            accu.append(test_accuracy)\n",
    "            print('test accuracy:', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd535c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,num_epochs=5):\n",
    "    since = time.time()\n",
    "    best_acc = 0.0\n",
    "    losses = []\n",
    "    accs = []\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoc{}/{}'.format(epoch,num_epochs-1))\n",
    "        print('-'*10)\n",
    "        # epoch一次完成后切换到测试phase\n",
    "        for phase in ['train','test']:\n",
    "            if phase == 'train':\n",
    "                model.train()   # 切换到train mode\n",
    "            else:\n",
    "                model.eval()\n",
    "                \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            \n",
    "            for inputs,labels in enumerate(dataloaders[phase]):\n",
    "                print(inputs.shape)\n",
    "                inputs = inputs.to(device)\n",
    "                labels_onehot =(torch.tensor(np.eye(100)[labels],dtype=torch.float32)).to(device)\n",
    "                optimizerAdam.zero_grad() # 梯度清零\n",
    "                # forwaard\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    print(outputs)\n",
    "                    y = nn.Softmax(dim=1)(outputs)\n",
    "                    loss = torch.nn.functional.binary_cross_entropy(y, labels_onehot)\n",
    "                    _, preds = torch.max(y.data,1) ##取每行最大\n",
    "                    print(y,preds)\n",
    "                    acc = accuracy_score(labels,preds,normalize=False)\n",
    "                    print('loss:{}, accu:{}'.format(loss,acc))\n",
    "\n",
    "                    # backward + optimize only if in trainning phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizerAdam.step()\n",
    "                        losses.append(loss.item())\n",
    "                \n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += acc\n",
    "                \n",
    "#             if phase == 'train':\n",
    "#                 epoch_loss = running_loss / 50\n",
    "#                 epoch_acc = running_corrects.double() / 50\n",
    "#                 print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase,epoch_loss,epoch_acc))\n",
    "                \n",
    "#             else:\n",
    "#                 epoch_loss = running_loss / 50\n",
    "#                 epoch_acc = running_corrects.double() / 50\n",
    "#                 print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase,epoch_loss,epoch_acc))\n",
    "               \n",
    "#                 if epoch_acc > best_acc:\n",
    "#                     best_acc = epoch_acc \n",
    "                    \n",
    "#                 if phase == \"test\":\n",
    "#                     if acc > best_acc:\n",
    "#                         best_acc = acc\n",
    "#                     accs.append(acc)\n",
    "                    \n",
    "#                 print('loss:{}, accu:{}'.format(sum(losses),acc))\n",
    "                \n",
    "                \n",
    "    for i in range(len(losses)):\n",
    "        writer.add_scalar(\"train_loss\",losses[i],i)  \n",
    "    for j in range(len(accs)):\n",
    "        writer.add_scalar(\"test_acc\",accs[i],i)  \n",
    "    \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Trainning complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60 , time_elapsed % 60\n",
    "    ))\n",
    "    print('Best test Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a603d61",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pr/fszw1bfs4l3_gds2ksx8rnbr0000gn/T/ipykernel_36561/1367997356.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "train_model(model,num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39f0a617",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation(augmentor,aug_batch):\n",
    "    if augmentor == 'cutout':\n",
    "        cutout = augment.Cutout(1,16)\n",
    "        img_batch_cutout,labels = cutout(aug_batch)\n",
    "        return img_batch_cutout,labels\n",
    "    if augmentor == 'mixup':\n",
    "        mixupor = augment.Mixup(0.5) ##设alpha\n",
    "        img_batch_mixup, labels = mixupor(aug_batch)\n",
    "        return img_batch_mixup, labels\n",
    "    if augmentor == 'cutmix':\n",
    "        cutmixer = augment.CutMix(0.5) ##设alpha\n",
    "        img_batch_mixup = cutmixer(aug_batch)\n",
    "        return img_batch_mixup, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce330daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_augment(model,criterion,optimizer,augmentor,num_epochs=1):\n",
    "    since = time.time()\n",
    "    best_acc = 0.0\n",
    "    losses = []\n",
    "    accs = []\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoc{}/{}'.format(epoch,num_epochs-1))\n",
    "        print('-'*10)\n",
    "        # epoch一次完成后切换到测试phase\n",
    "        for phase in ['train','test']:\n",
    "            if phase == 'train':\n",
    "                model.train()   \n",
    "            else:\n",
    "                model.eval()\n",
    "            \n",
    "            for ori_inputs,ori_labels in tqdm(dataloaders[phase]):\n",
    "                if phase == 'train':\n",
    "                    \n",
    "                    aug_batch = []\n",
    "                    for i in range(n):\n",
    "                        tup = (ori_inputs[i],ori_labels[i])\n",
    "                        aug_batch.append(tup)\n",
    "                    if augmentor == 'cutout':\n",
    "                        train_batch, train_batch_labels = augmentation(augmentor,aug_batch)\n",
    "                    if augmentor == 'cutmix' or augmentor == 'mixup':\n",
    "                        train_batch, train_batch_labels = augmentation(augmentor,aug_batch)\n",
    "                    inputs = train_batch.to(device)\n",
    "                    labels = train_batch_labels.to(device)\n",
    "                    \n",
    "                else:\n",
    "                    inputs = ori_inputs.to(device)\n",
    "                    labels =(torch.tensor(np.eye(100)[ori_labels],dtype=torch.float32)).to(device)\n",
    "                    \n",
    "                optimizer.zero_grad() # 梯度清零\n",
    "                \n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    y = torch.nn.Softmax(dim=-1)(outputs)\n",
    "                    loss = torch.nn.functional.binary_cross_entropy(y, labels)\n",
    "                    _, preds =torch.max(y,1) ##取每行最大\n",
    "                    acc = accuracy_score(preds, ori_labels)\n",
    "                    print('loss:{}, accu:{}'.format(loss,acc))\n",
    "\n",
    "                    # backward + optimize only if in trainning phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        losses.append(loss.item())\n",
    "                    \n",
    "                if phase == \"test\":\n",
    "                    if acc > best_acc:\n",
    "                        best_acc = acc\n",
    "                    accs.append(acc)\n",
    "                \n",
    "                \n",
    "    for i in range(len(losses)):\n",
    "        writer.add_scalar(\"train_loss\",losses[i],i)  \n",
    "    for j in range(len(accs)):\n",
    "        writer.add_scalar(\"test_acc\",accs[i],i)  \n",
    "    \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Trainning complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60 , time_elapsed % 60\n",
    "    ))\n",
    "    print('Best test Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eef574a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoc0/0\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                   | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "<class 'torch.Tensor'> 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/500 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pr/fszw1bfs4l3_gds2ksx8rnbr0000gn/T/ipykernel_33144/966741956.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model_augment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizerAdam\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'cutout'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/pr/fszw1bfs4l3_gds2ksx8rnbr0000gn/T/ipykernel_33144/506702160.py\u001b[0m in \u001b[0;36mtrain_model_augment\u001b[0;34m(model, criterion, optimizer, augmentor, num_epochs)\u001b[0m\n\u001b[1;32m     43\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                     \u001b[0;31m# backward + optimize only if in trainning phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/pytorch_env/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/pytorch_env/lib/python3.9/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1048\u001b[0m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/pytorch_env/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2688\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2689\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2690\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/pytorch_env/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlog_softmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1670\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"log_softmax\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1672\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1673\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1674\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "train_model_augment(model,loss_func,optimizerAdam,'cutout',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c97367a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env_kernel",
   "language": "python",
   "name": "pytorch_env_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
